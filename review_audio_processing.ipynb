{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "import librosa \n",
    "from tqdm import tqdm\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013037a1d45cc33460806cc3f8ecee9d536c45639ba4c...</td>\n",
       "      <td>common_voice_en_699711.mp3</td>\n",
       "      <td>She'll be all right.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001509f4624a7dee75247f6a8b642c4a0d09f8be3eeea6...</td>\n",
       "      <td>common_voice_en_18132047.mp3</td>\n",
       "      <td>All's well that ends well.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003fb666a99eb3aa3ba05d9c8641c18e55cf7d34d1b981...</td>\n",
       "      <td>common_voice_en_17263741.mp3</td>\n",
       "      <td>Do you mean it?</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004017ba82a23768d58dff3b91da8e8f951ea5fb6d3cd9...</td>\n",
       "      <td>common_voice_en_17893917.mp3</td>\n",
       "      <td>The new patch is less invasive than the old on...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0047f1aea3f39c4c6a9298d84f046c1f84f439f594d840...</td>\n",
       "      <td>common_voice_en_17561821.mp3</td>\n",
       "      <td>How is Mozilla going to handle ambiguities lik...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  0013037a1d45cc33460806cc3f8ecee9d536c45639ba4c...   \n",
       "1  001509f4624a7dee75247f6a8b642c4a0d09f8be3eeea6...   \n",
       "2  003fb666a99eb3aa3ba05d9c8641c18e55cf7d34d1b981...   \n",
       "3  004017ba82a23768d58dff3b91da8e8f951ea5fb6d3cd9...   \n",
       "4  0047f1aea3f39c4c6a9298d84f046c1f84f439f594d840...   \n",
       "\n",
       "                           path  \\\n",
       "0    common_voice_en_699711.mp3   \n",
       "1  common_voice_en_18132047.mp3   \n",
       "2  common_voice_en_17263741.mp3   \n",
       "3  common_voice_en_17893917.mp3   \n",
       "4  common_voice_en_17561821.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0                               She'll be all right.         2           1   \n",
       "1                         All's well that ends well.         2           0   \n",
       "2                                    Do you mean it?         2           0   \n",
       "3  The new patch is less invasive than the old on...         2           1   \n",
       "4  How is Mozilla going to handle ambiguities lik...         2           0   \n",
       "\n",
       "   age gender accent  \n",
       "0  NaN    NaN    NaN  \n",
       "1  NaN    NaN    NaN  \n",
       "2  NaN    NaN    NaN  \n",
       "3  NaN    NaN    NaN  \n",
       "4  NaN    NaN    NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "temp_dir = tempfile.gettempdir()\n",
    "# common_voice_path=os.path.abspath(\"../transaccent/data/en\")\n",
    "common_voice_path=os.path.abspath(\"/data\")\n",
    "audio_files_path = os.path.join(common_voice_path, \"clips\")\n",
    "data_file_filename = \"validated.tsv\"\n",
    "data_file_path = os.path.join(common_voice_path, data_file_filename)\n",
    "\n",
    "# Retreive records\n",
    "df = pd.read_csv(data_file_path, sep='\\t', low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00c3f0e7c691ef30257d1bfa9adc410535b7ba3f48e344...</td>\n",
       "      <td>common_voice_en_18295850.mp3</td>\n",
       "      <td>The long-lived bridge still stands today.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>05ba9bb1a4ac391849fa4461547967768f4d7df8ee52d7...</td>\n",
       "      <td>common_voice_en_19967535.mp3</td>\n",
       "      <td>The cemetery is now managed by three trusts.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>fifties</td>\n",
       "      <td>male</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>06546553aed17027b4e638d4afb56f39b216026088cf40...</td>\n",
       "      <td>common_voice_en_17147389.mp3</td>\n",
       "      <td>Women form less than half of the group.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0838a82655be5a61349c2d2d86b60c22b5b84fea9826cb...</td>\n",
       "      <td>common_voice_en_18127728.mp3</td>\n",
       "      <td>Sunburn can be avoided by applying sunscreen o...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0899979e8d43a9faf448ddb5f4fc9a38a0fb4c120eaf34...</td>\n",
       "      <td>common_voice_en_17850951.mp3</td>\n",
       "      <td>Still waters run deep.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             client_id  \\\n",
       "9    00c3f0e7c691ef30257d1bfa9adc410535b7ba3f48e344...   \n",
       "70   05ba9bb1a4ac391849fa4461547967768f4d7df8ee52d7...   \n",
       "81   06546553aed17027b4e638d4afb56f39b216026088cf40...   \n",
       "100  0838a82655be5a61349c2d2d86b60c22b5b84fea9826cb...   \n",
       "104  0899979e8d43a9faf448ddb5f4fc9a38a0fb4c120eaf34...   \n",
       "\n",
       "                             path  \\\n",
       "9    common_voice_en_18295850.mp3   \n",
       "70   common_voice_en_19967535.mp3   \n",
       "81   common_voice_en_17147389.mp3   \n",
       "100  common_voice_en_18127728.mp3   \n",
       "104  common_voice_en_17850951.mp3   \n",
       "\n",
       "                                              sentence  up_votes  down_votes  \\\n",
       "9            The long-lived bridge still stands today.         2           0   \n",
       "70        The cemetery is now managed by three trusts.         2           0   \n",
       "81             Women form less than half of the group.         2           0   \n",
       "100  Sunburn can be avoided by applying sunscreen o...         2           0   \n",
       "104                             Still waters run deep.         2           0   \n",
       "\n",
       "          age gender   accent  \n",
       "9    twenties   male      NaN  \n",
       "70    fifties   male  african  \n",
       "81   twenties   male       us  \n",
       "100  twenties   male      NaN  \n",
       "104  twenties   male    other  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['down_votes'] < 1) & (df['gender'] == 'male') & (df['up_votes'] > 1)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from data_util import build_speaker_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>720300</th>\n",
       "      <td>d0b62ac1e57e267f16088ee614cdaf09a9826c3b704ce2...</td>\n",
       "      <td>common_voice_en_17246192.mp3</td>\n",
       "      <td>How do you know that?</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720301</th>\n",
       "      <td>d0b62ac1e57e267f16088ee614cdaf09a9826c3b704ce2...</td>\n",
       "      <td>common_voice_en_17246193.mp3</td>\n",
       "      <td>Where did it come from then?</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720302</th>\n",
       "      <td>d0b62ac1e57e267f16088ee614cdaf09a9826c3b704ce2...</td>\n",
       "      <td>common_voice_en_17246200.mp3</td>\n",
       "      <td>Look, the seam is now broken, it couldn't stan...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720303</th>\n",
       "      <td>d0b62ac1e57e267f16088ee614cdaf09a9826c3b704ce2...</td>\n",
       "      <td>common_voice_en_17246201.mp3</td>\n",
       "      <td>What did he do?</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720304</th>\n",
       "      <td>d0b62ac1e57e267f16088ee614cdaf09a9826c3b704ce2...</td>\n",
       "      <td>common_voice_en_17246202.mp3</td>\n",
       "      <td>According to the dictionary, the word \"gizmo\" ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                client_id  \\\n",
       "720300  d0b62ac1e57e267f16088ee614cdaf09a9826c3b704ce2...   \n",
       "720301  d0b62ac1e57e267f16088ee614cdaf09a9826c3b704ce2...   \n",
       "720302  d0b62ac1e57e267f16088ee614cdaf09a9826c3b704ce2...   \n",
       "720303  d0b62ac1e57e267f16088ee614cdaf09a9826c3b704ce2...   \n",
       "720304  d0b62ac1e57e267f16088ee614cdaf09a9826c3b704ce2...   \n",
       "\n",
       "                                path  \\\n",
       "720300  common_voice_en_17246192.mp3   \n",
       "720301  common_voice_en_17246193.mp3   \n",
       "720302  common_voice_en_17246200.mp3   \n",
       "720303  common_voice_en_17246201.mp3   \n",
       "720304  common_voice_en_17246202.mp3   \n",
       "\n",
       "                                                 sentence  up_votes  \\\n",
       "720300                              How do you know that?         2   \n",
       "720301                       Where did it come from then?         3   \n",
       "720302  Look, the seam is now broken, it couldn't stan...         2   \n",
       "720303                                    What did he do?         2   \n",
       "720304  According to the dictionary, the word \"gizmo\" ...         2   \n",
       "\n",
       "        down_votes       age gender  accent  \n",
       "720300           0  twenties   male  indian  \n",
       "720301           0  twenties   male  indian  \n",
       "720302           0  twenties   male  indian  \n",
       "720303           0  twenties   male  indian  \n",
       "720304           0  twenties   male  indian  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indian_df = build_speaker_dataset(df[(df['accent'] == 'indian') ], 1)\n",
    "indian_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>837785</th>\n",
       "      <td>b419faab633f2099c6405ff157b4d9fb5675219570f268...</td>\n",
       "      <td>common_voice_en_84125.mp3</td>\n",
       "      <td>I said I was trying to catch one.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837786</th>\n",
       "      <td>b419faab633f2099c6405ff157b4d9fb5675219570f268...</td>\n",
       "      <td>common_voice_en_84126.mp3</td>\n",
       "      <td>Judge may not think so.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837787</th>\n",
       "      <td>b419faab633f2099c6405ff157b4d9fb5675219570f268...</td>\n",
       "      <td>common_voice_en_84127.mp3</td>\n",
       "      <td>Don‘t fight fire with fire, it would not help.</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837788</th>\n",
       "      <td>b419faab633f2099c6405ff157b4d9fb5675219570f268...</td>\n",
       "      <td>common_voice_en_84128.mp3</td>\n",
       "      <td>But he'd have to.</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837789</th>\n",
       "      <td>b419faab633f2099c6405ff157b4d9fb5675219570f268...</td>\n",
       "      <td>common_voice_en_84129.mp3</td>\n",
       "      <td>Whose turn is it?</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                client_id  \\\n",
       "837785  b419faab633f2099c6405ff157b4d9fb5675219570f268...   \n",
       "837786  b419faab633f2099c6405ff157b4d9fb5675219570f268...   \n",
       "837787  b419faab633f2099c6405ff157b4d9fb5675219570f268...   \n",
       "837788  b419faab633f2099c6405ff157b4d9fb5675219570f268...   \n",
       "837789  b419faab633f2099c6405ff157b4d9fb5675219570f268...   \n",
       "\n",
       "                             path  \\\n",
       "837785  common_voice_en_84125.mp3   \n",
       "837786  common_voice_en_84126.mp3   \n",
       "837787  common_voice_en_84127.mp3   \n",
       "837788  common_voice_en_84128.mp3   \n",
       "837789  common_voice_en_84129.mp3   \n",
       "\n",
       "                                              sentence  up_votes  down_votes  \\\n",
       "837785               I said I was trying to catch one.         2           0   \n",
       "837786                         Judge may not think so.         2           0   \n",
       "837787  Don‘t fight fire with fire, it would not help.         3           0   \n",
       "837788                               But he'd have to.         3           0   \n",
       "837789                               Whose turn is it?         2           0   \n",
       "\n",
       "             age gender accent  \n",
       "837785  thirties   male     us  \n",
       "837786  thirties   male     us  \n",
       "837787  thirties   male     us  \n",
       "837788  thirties   male     us  \n",
       "837789  thirties   male     us  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_df = build_speaker_dataset(df[df['accent'] == 'us'], 1)\n",
    "us_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 576 records with indian accents and 7827 records with us accents\n"
     ]
    }
   ],
   "source": [
    "print(f\"Retrieved {len(indian_df)} records with indian accents and {len(us_df)} records with us accents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hop=192               #hop size (window size = 6*hop)\n",
    "sr=16000              #sampling rate\n",
    "min_level_db=-100     #reference values to normalize data\n",
    "ref_level_db=20\n",
    "\n",
    "shape=24              #length of time axis of split specrograms to feed to generator            \n",
    "vec_len=128           #length of vector generated by siamese vector\n",
    "# bs = 16               #batch size\n",
    "bs = 32               #batch size\n",
    "delta = 2.            #constant for siamese loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class HParams:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152\n",
      "40\n",
      "1152\n",
      "240\n",
      "24064\n"
     ]
    }
   ],
   "source": [
    "from yaml import load, dump\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper\n",
    "\n",
    "with open(\"hparams.yaml\", \"r\") as fp:\n",
    "    hparams_yaml = load(fp, Loader=Loader)\n",
    "\n",
    "hparams = HParams(**hparams_yaml)\n",
    "hparams.n_fft = 6 * hparams.hop\n",
    "hparams.win_length = 6 * hparams.hop\n",
    "hparams.max_spec_length = 10 * hparams.shape \n",
    "hparams.max_audio_samples = 256 * 94\n",
    "\n",
    "print(hparams.n_fft)\n",
    "print(hparams.trim_top_db)\n",
    "print(hparams.win_length)\n",
    "print(hparams.max_spec_length)\n",
    "print(hparams.max_audio_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def pad_audio_with_silence(wav, pad_value, hparams):\n",
    "    if len(wav) < hparams.max_audio_samples:\n",
    "        pad_samples = hparams.max_audio_samples - len(wav)\n",
    "        wav = np.pad(wav, (0, pad_samples), mode='constant', constant_values=pad_value)\n",
    "    \n",
    "    return wav\n",
    "\n",
    "def trim_silence(wav, hparams):\n",
    "    return librosa.effects.trim(wav, top_db=hparams.trim_top_db, frame_length=hparams.trim_fft_size, hop_length=hparams.trim_hop_size)[0]\n",
    "\n",
    "def load_audio(audio_file_name, hparams):\n",
    "    # The loading of mp3 files throw a warning, due to the volume of files we ignore this warning\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    y, _= librosa.load(audio_file_name, sr=hparams.sample_rate)\n",
    "    return y\n",
    "\n",
    "def convert_mp3_to_signal(audio_file_name, hparams):\n",
    "    y = load_audio(audio_file_name, hparams)\n",
    "    if hparams.trim_silence:\n",
    "        y = trim_silence(y, hparams)\n",
    "    # pad to try to make all the audio files the same length\n",
    "    y = pad_audio_with_silence(y, pad_value=0., hparams=hparams)\n",
    "    return y\n",
    "\n",
    "def process_audio(audio_path, hparams):\n",
    "    return np.array(convert_mp3_to_signal(os.path.join(audio_files_path, audio_path), hparams))\n",
    "\n",
    "def audio_array_for_accent(df, accent, hparams, limit_size=-1, tqdm=lambda x: x):\n",
    "    import multiprocessing\n",
    "    import numpy as np\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    \n",
    "    input_mp3_files = df[df['accent'] == accent]['path'].to_numpy() \n",
    "    \n",
    "    if limit_size > 0:\n",
    "        print(f\"Retrieved {len(input_mp3_files)} will only be using {limit_size}\")\n",
    "        input_mp3_files = input_mp3_files[:limit_size]\n",
    "    \n",
    "    executor = ProcessPoolExecutor(max_workers=cpu_count)\n",
    "    futures = []\n",
    "    index = 1\n",
    "    \n",
    "    for filepath in input_mp3_files:\n",
    "        futures.append(executor.submit(partial(process_audio, filepath, hparams)))\n",
    "        index += 1\n",
    "    \n",
    "    return np.array([future.result() for future in tqdm(futures) if future.result() is not None])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def melspecfunc(waveform, hparams):\n",
    "    return librosa.feature.melspectrogram(y=waveform, \n",
    "                                          sr=hparams.sample_rate, \n",
    "                                          n_fft=hparams.n_fft, \n",
    "                                          win_length=hparams.win_length,\n",
    "                                          hop_length=hparams.hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def normalize(S, hparams):\n",
    "    return np.clip((((S - hparams.min_level_db) / -hparams.min_level_db)*2.)-1., -1, 1)\n",
    "\n",
    "def prep(wv, hparams):\n",
    "    S = np.array(melspecfunc(wv, hparams))\n",
    "    S = librosa.power_to_db(S)-hparams.ref_level_db\n",
    "    return normalize(S, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def process_wav(wav, hparams):\n",
    "    S = np.array(prep(wav, hparams), dtype=np.float32)\n",
    "    return np.expand_dims(S, -1)\n",
    "\n",
    "def tospec(wvs, hparams):\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(cpu_count)\n",
    "    specs = pool.map(partial(process_wav, hparams=hparams), wvs)\n",
    "    \n",
    "    return specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# split into equal chunk size\n",
    "def split_spec(spec, chunk_size):\n",
    "    return [spec[i * chunk_size: (i+1) * chunk_size] for i in range(int(np.ceil(len(spec) / chunk_size)))]\n",
    "\n",
    "def splitcut(data, hparams):\n",
    "    chunk_size = hparams.max_spec_length                                                             #max spectrogram length\n",
    "    \n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(cpu_count)\n",
    "    splits = pool.map(partial(split_spec,chunk_size=chunk_size), data)\n",
    "    \n",
    "    return np.array(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "input_accent = 'indian'\n",
    "target_accent = 'us'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 576 will only be using 576\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (128,126,1) into shape (128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-72875e6aa61d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mawv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_array_for_accent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindian_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_accent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindian_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtospec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mawv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0madata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-852b3f054fec>\u001b[0m in \u001b[0;36msplitcut\u001b[0;34m(data, hparams)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (128,126,1) into shape (128)"
     ]
    }
   ],
   "source": [
    "awv = audio_array_for_accent(indian_df, input_accent, hparams, limit_size=len(indian_df))\n",
    "aspec = tospec(awv, hparams)\n",
    "adata = splitcut(aspec, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bwv = audio_array_for_accent(us_df, target_accent, hparams, limit_size=len(us_df))\n",
    "bspec = tospec(bwv, hparams)\n",
    "bdata = splitcut(bspec, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "indian_dir = '/data/wav/v2/indian'\n",
    "us_dir = '/data/wav/v2/us'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "np.savez(f'{indian_dir}/data.npz', spec=aspec, data=adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "np.savez(f'{indian_dir}/data.npz', spec=bspec, data=bdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
