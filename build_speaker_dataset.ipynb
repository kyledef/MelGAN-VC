{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import librosa \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00c3f0e7c691ef30257d1bfa9adc410535b7ba3f48e344...</td>\n",
       "      <td>common_voice_en_18295850.mp3</td>\n",
       "      <td>The long-lived bridge still stands today.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>05ba9bb1a4ac391849fa4461547967768f4d7df8ee52d7...</td>\n",
       "      <td>common_voice_en_19967535.mp3</td>\n",
       "      <td>The cemetery is now managed by three trusts.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>fifties</td>\n",
       "      <td>male</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>06546553aed17027b4e638d4afb56f39b216026088cf40...</td>\n",
       "      <td>common_voice_en_17147389.mp3</td>\n",
       "      <td>Women form less than half of the group.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0838a82655be5a61349c2d2d86b60c22b5b84fea9826cb...</td>\n",
       "      <td>common_voice_en_18127728.mp3</td>\n",
       "      <td>Sunburn can be avoided by applying sunscreen o...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0899979e8d43a9faf448ddb5f4fc9a38a0fb4c120eaf34...</td>\n",
       "      <td>common_voice_en_17850951.mp3</td>\n",
       "      <td>Still waters run deep.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             client_id  \\\n",
       "9    00c3f0e7c691ef30257d1bfa9adc410535b7ba3f48e344...   \n",
       "70   05ba9bb1a4ac391849fa4461547967768f4d7df8ee52d7...   \n",
       "81   06546553aed17027b4e638d4afb56f39b216026088cf40...   \n",
       "100  0838a82655be5a61349c2d2d86b60c22b5b84fea9826cb...   \n",
       "104  0899979e8d43a9faf448ddb5f4fc9a38a0fb4c120eaf34...   \n",
       "\n",
       "                             path  \\\n",
       "9    common_voice_en_18295850.mp3   \n",
       "70   common_voice_en_19967535.mp3   \n",
       "81   common_voice_en_17147389.mp3   \n",
       "100  common_voice_en_18127728.mp3   \n",
       "104  common_voice_en_17850951.mp3   \n",
       "\n",
       "                                              sentence  up_votes  down_votes  \\\n",
       "9            The long-lived bridge still stands today.         2           0   \n",
       "70        The cemetery is now managed by three trusts.         2           0   \n",
       "81             Women form less than half of the group.         2           0   \n",
       "100  Sunburn can be avoided by applying sunscreen o...         2           0   \n",
       "104                             Still waters run deep.         2           0   \n",
       "\n",
       "          age gender   accent  \n",
       "9    twenties   male      NaN  \n",
       "70    fifties   male  african  \n",
       "81   twenties   male       us  \n",
       "100  twenties   male      NaN  \n",
       "104  twenties   male    other  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir = tempfile.gettempdir()\n",
    "common_voice_path=os.path.abspath(\"/data\")\n",
    "audio_files_path = os.path.join(common_voice_path, \"clips\")\n",
    "data_file_filename = \"validated.tsv\"\n",
    "data_file_path = os.path.join(common_voice_path, data_file_filename)\n",
    "df = pd.read_csv(data_file_path, sep='\\t', low_memory=False)\n",
    "df = df[(df['down_votes'] < 1) & (df['gender'] == 'male') & (df['up_votes'] > 1)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Description\n",
    "We would like to build a one to one dataset for indian to us conversion. \n",
    "\n",
    "We will take the highest frequency speaker from both accents and attempt to convert between each other.\n",
    "\n",
    "The general steps are:\n",
    "1. Find the speakers with the highest number of sentences spoken\n",
    "2. Convert data from mp3 to wav\n",
    "3. Store into individual folder to be reused by other experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from data_util import build_speaker_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "indian_df = build_speaker_dataset(df[(df['accent'] == 'indian') ], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "us_df = build_speaker_dataset(df[df['accent'] == 'us'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 576 records with indian accents and 7827 records with us accents\n"
     ]
    }
   ],
   "source": [
    "print(f\"Retrieved {len(indian_df)} records with indian accents and {len(us_df)} records with us accents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def mp3_to_wav(src_path, target_path):\n",
    "    \"\"\"\n",
    "    Read mp3 file from source path, convert it to wav and write it to target path. \n",
    "    Necessary libraries: ffmpeg, libav.\n",
    "\n",
    "    :param src_path: source mp3 file path\n",
    "    :param target_path: target wav file path\n",
    "    \"\"\"\n",
    "    basepath, filename = os.path.split(src_path)\n",
    "    os.chdir(basepath)\n",
    "    AudioSegment.from_mp3(src_path).export(target_path, format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def process_each_file(audio_file_name, audio_files_path, output_dir):\n",
    "    audio_file_name_mp3 = os.path.join(audio_files_path, audio_file_name)\n",
    "    audio_file_name_wav = audio_file_name.replace(\".mp3\", \".wav\")\n",
    "    target_file_path = os.path.join(output_dir, audio_file_name_wav)\n",
    "    mp3_to_wav(audio_file_name_mp3, target_file_path)\n",
    "    return target_file_path\n",
    "\n",
    "def convert_to_wav(df, audio_files_path, output_dir):\n",
    "    input_mp3_files = df['path'].to_numpy()\n",
    "    \n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(cpu_count)\n",
    "    specs = pool.map(partial(process_each_file, audio_files_path=audio_files_path, output_dir=output_dir), input_mp3_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def create_dataset(df, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "    return convert_to_wav(df, audio_files_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "indian_output_dir = \"/data/wav/v2/indian\"\n",
    "us_output_dir = \"/data/wav/v2/us\"\n",
    "us_output_dir_small = \"/data/wav/v2/us_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "indian_wav_files = create_dataset(indian_df, indian_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "us_wav_files = create_dataset(us_df, us_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Create a smaller subset of the us voice with the same size as the indian dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "desired_num_records = len(os.listdir(indian_output_dir))\n",
    "full_us_records = os.listdir(us_output_dir)\n",
    "desired_us_records = full_us_records[:desired_num_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "!rm -rf /data/wav/v2/us_small\n",
    "!mkdir -p /data/wav/v2/us_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for file_name in desired_us_records:\n",
    "    shutil.copyfile(os.path.join(us_output_dir, file_name), os.path.join(us_output_dir_small, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(us_output_dir_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
